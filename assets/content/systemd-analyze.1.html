<pre>
       <b>systemd-analyze </b>may be used to determine system boot-up
       performance statistics and retrieve other state and tracing
       information from the system and service manager, and to verify
       the correctness of unit files. It is also used to access special
       functions useful for advanced system manager debugging.

       If no command is passed, <b>systemd-analyze time </b>is implied.

   <b>systemd-analyze time</b>
       This command prints the time spent in the kernel before userspace
       has been reached, the time spent in the initial RAM disk (initrd)
       before normal system userspace has been reached, and the time
       normal system userspace took to initialize. Note that these
       measurements simply measure the time passed up to the point where
       all system services have been spawned, but not necessarily until
       they fully finished initialization or the disk is idle.

       <b>Example 1. Show how long the boot took</b>

           # in a container
           $ systemd-analyze time
           Startup finished in 296ms (userspace)
           multi-user.target reached after 275ms in userspace

           # on a real machine
           $ systemd-analyze time
           Startup finished in 2.584s (kernel) + 19.176s (initrd) + 47.847s (userspace) = 1min 9.608s
           multi-user.target reached after 47.820s in userspace

   <b>systemd-analyze blame</b>
       This command prints a list of all running units, ordered by the
       time they took to initialize. This information may be used to
       optimize boot-up times. Note that the output might be misleading
       as the initialization of one service might be slow simply because
       it waits for the initialization of another service to complete.
       Also note: <b>systemd-analyze blame </b>doesn't display results for
       services with <i>Type=simple</i>, because systemd considers such
       services to be started immediately, hence no measurement of the
       initialization delays can be done. Also note that this command
       only shows the time units took for starting up, it does not show
       how long unit jobs spent in the execution queue. In particular it
       shows the time units spent in "activating" state, which is not
       defined for units such as device units that transition directly
       from "inactive" to "active". This command hence gives an
       impression of the performance of program code, but cannot
       accurately reflect latency introduced by waiting for hardware and
       similar events.

       <b>Example 2. Show which units took the most time during boot</b>

           $ systemd-analyze blame
                    32.875s pmlogger.service
                    20.905s systemd-networkd-wait-online.service
                    13.299s dev-vda1.device
                    ...
                       23ms sysroot.mount
                       11ms initrd-udevadm-cleanup-db.service
                        3ms sys-kernel-config.mount

   <b>systemd-analyze critical-chain [</b><i>UNIT</i>...]
       This command prints a tree of the time-critical chain of units
       (for each of the specified <i>UNIT</i>s or for the default target
       otherwise). The time after the unit is active or started is
       printed after the "@" character. The time the unit takes to start
       is printed after the "+" character. Note that the output might be
       misleading as the initialization of services might depend on
       socket activation and because of the parallel execution of units.
       Also, similar to the <b>blame </b>command, this only takes into account
       the time units spent in "activating" state, and hence does not
       cover units that never went through an "activating" state (such
       as device units that transition directly from "inactive" to
       "active"). Moreover it does not show information on jobs (and in
       particular not jobs that timed out).

       <b>Example 3. systemd-analyze critical-chain</b>

           $ systemd-analyze critical-chain
           multi-user.target @47.820s
           └─pmie.service @35.968s +548ms
             └─pmcd.service @33.715s +2.247s
               └─network-online.target @33.712s
                 └─systemd-networkd-wait-online.service @12.804s +20.905s
                   └─systemd-networkd.service @11.109s +1.690s
                     └─systemd-udevd.service @9.201s +1.904s
                       └─systemd-tmpfiles-setup-dev.service @7.306s +1.776s
                         └─kmod-static-nodes.service @6.976s +177ms
                           └─systemd-journald.socket
                             └─system.slice
                               └─-.slice

   <b>systemd-analyze dump</b>
       This command outputs a (usually very long) human-readable
       serialization of the complete server state. Its format is subject
       to change without notice and should not be parsed by
       applications.

       <b>Example 4. Show the internal state of user manager</b>

           $ systemd-analyze --user dump
           Timestamp userspace: Thu 2019-03-14 23:28:07 CET
           Timestamp finish: Thu 2019-03-14 23:28:07 CET
           Timestamp generators-start: Thu 2019-03-14 23:28:07 CET
           Timestamp generators-finish: Thu 2019-03-14 23:28:07 CET
           Timestamp units-load-start: Thu 2019-03-14 23:28:07 CET
           Timestamp units-load-finish: Thu 2019-03-14 23:28:07 CET
           -&gt; Unit proc-timer_list.mount:
                   Description: /proc/timer_list
                   ...
           -&gt; Unit default.target:
                   Description: Main user target
           ...

   <b>systemd-analyze plot</b>
       This command prints an SVG graphic detailing which system
       services have been started at what time, highlighting the time
       they spent on initialization.

       <b>Example 5. Plot a bootchart</b>

           $ systemd-analyze plot &gt;bootup.svg
           $ eog bootup.svg&amp;

   <b>systemd-analyze dot [</b><i>pattern</i>...]
       This command generates textual dependency graph description in
       dot format for further processing with the GraphViz <b>dot</b>(1) tool.
       Use a command line like <b>systemd-analyze dot | dot -Tsvg</b>
       <b>&gt;systemd.svg </b>to generate a graphical dependency tree. Unless
       <b>--order </b>or <b>--require </b>is passed, the generated graph will show
       both ordering and requirement dependencies. Optional pattern
       globbing style specifications (e.g.  *.target) may be given at
       the end. A unit dependency is included in the graph if any of
       these patterns match either the origin or destination node.

       <b>Example 6. Plot all dependencies of any unit whose name starts</b>
       <b>with "avahi-daemon"</b>

           $ systemd-analyze dot 'avahi-daemon.*' | dot -Tsvg &gt;avahi.svg
           $ eog avahi.svg

       <b>Example 7. Plot the dependencies between all known target units</b>

           $ systemd-analyze dot --to-pattern='*.target' --from-pattern='*.target' \
                 | dot -Tsvg &gt;targets.svg
           $ eog targets.svg

   <b>systemd-analyze unit-paths</b>
       This command outputs a list of all directories from which unit
       files, .d overrides, and .wants, .requires symlinks may be
       loaded. Combine with <b>--user </b>to retrieve the list for the user
       manager instance, and <b>--global </b>for the global configuration of
       user manager instances.

       <b>Example 8. Show all paths for generated units</b>

           $ systemd-analyze unit-paths | grep '^/run'
           /run/systemd/system.control
           /run/systemd/transient
           /run/systemd/generator.early
           /run/systemd/system
           /run/systemd/system.attached
           /run/systemd/generator
           /run/systemd/generator.late

       Note that this verb prints the list that is compiled into
       <b>systemd-analyze </b>itself, and does not communicate with the running
       manager. Use

           systemctl [--user] [--global] show -p UnitPath --value

       to retrieve the actual list that the manager uses, with any empty
       directories omitted.

   <b>systemd-analyze exit-status [</b><i>STATUS</i>...]
       This command prints a list of exit statuses along with their
       "class", i.e. the source of the definition (one of "glibc",
       "systemd", "LSB", or "BSD"), see the Process Exit Codes section
       in <a href="https://man7.org/linux/man-pages/man5/systemd.exec.5.html">systemd.exec(5)</a>. If no additional arguments are specified, all
       known statuses are shown. Otherwise, only the definitions for the
       specified codes are shown.

       <b>Example 9. Show some example exit status names</b>

           $ systemd-analyze exit-status 0 1 {63..65}
           NAME    STATUS CLASS
           SUCCESS 0      glibc
           FAILURE 1      glibc
           -       63     -
           USAGE   64     BSD
           DATAERR 65     BSD

   <b>systemd-analyze capability [</b><i>CAPABILITY</i>...]
       This command prints a list of Linux capabilities along with their
       numeric IDs. See <a href="https://man7.org/linux/man-pages/man7/capabilities.7.html">capabilities(7)</a> for details. If no argument is
       specified the full list of capabilities known to the service
       manager and the kernel is shown. Capabilities defined by the
       kernel but not known to the service manager are shown as
       "cap_???". Optionally, if arguments are specified they may refer
       to specific cabilities by name or numeric ID, in which case only
       the indicated capabilities are shown in the table.

       <b>Example 10. Show some example capability names</b>

           $ systemd-analyze capability 0 1 {30..32}
           NAME              NUMBER
           cap_chown              0
           cap_dac_override       1
           cap_audit_control     30
           cap_setfcap           31
           cap_mac_override      32

   <b>systemd-analyze condition </b><i>CONDITION</i>...
       This command will evaluate <i>Condition*=...</i>  and <i>Assert*=...</i>
       assignments, and print their values, and the resulting value of
       the combined condition set. See <a href="https://man7.org/linux/man-pages/man5/systemd.unit.5.html">systemd.unit(5)</a> for a list of
       available conditions and asserts.

       <b>Example 11. Evaluate conditions that check kernel versions</b>

           $ systemd-analyze condition 'ConditionKernelVersion = ! &lt;4.0' \
                   'ConditionKernelVersion = &gt;=5.1' \
                   'ConditionACPower=|false' \
                   'ConditionArchitecture=|!arm' \
                   'AssertPathExists=/etc/os-release'
           test.service: AssertPathExists=/etc/os-release succeeded.
           Asserts succeeded.
           test.service: ConditionArchitecture=|!arm succeeded.
           test.service: ConditionACPower=|false failed.
           test.service: ConditionKernelVersion=&gt;=5.1 succeeded.
           test.service: ConditionKernelVersion=!&lt;4.0 succeeded.
           Conditions succeeded.

   <b>systemd-analyze syscall-filter [</b><i>SET</i>...]
       This command will list system calls contained in the specified
       system call set <i>SET</i>, or all known sets if no sets are specified.
       Argument <i>SET</i> must include the "@" prefix.

   <b>systemd-analyze calendar </b><i>EXPRESSION</i>...
       This command will parse and normalize repetitive calendar time
       events, and will calculate when they elapse next. This takes the
       same input as the <i>OnCalendar=</i> setting in <a href="https://man7.org/linux/man-pages/man5/systemd.timer.5.html">systemd.timer(5)</a>,
       following the syntax described in <a href="https://man7.org/linux/man-pages/man7/systemd.time.7.html">systemd.time(7)</a>. By default,
       only the next time the calendar expression will elapse is shown;
       use <b>--iterations= </b>to show the specified number of next times the
       expression elapses. Each time the expression elapses forms a
       timestamp, see the <b>timestamp </b>verb below.

       <b>Example 12. Show leap days in the near future</b>

           $ systemd-analyze calendar --iterations=5 '*-2-29 0:0:0'
             Original form: *-2-29 0:0:0
           Normalized form: *-02-29 00:00:00
               Next elapse: Sat 2020-02-29 00:00:00 UTC
                  From now: 11 months 15 days left
                  Iter. #2: Thu 2024-02-29 00:00:00 UTC
                  From now: 4 years 11 months left
                  Iter. #3: Tue 2028-02-29 00:00:00 UTC
                  From now: 8 years 11 months left
                  Iter. #4: Sun 2032-02-29 00:00:00 UTC
                  From now: 12 years 11 months left
                  Iter. #5: Fri 2036-02-29 00:00:00 UTC
                  From now: 16 years 11 months left

   <b>systemd-analyze timestamp </b><i>TIMESTAMP</i>...
       This command parses a timestamp (i.e. a single point in time) and
       outputs the normalized form and the difference between this
       timestamp and now. The timestamp should adhere to the syntax
       documented in <a href="https://man7.org/linux/man-pages/man7/systemd.time.7.html">systemd.time(7)</a>, section "PARSING TIMESTAMPS".

       <b>Example 13. Show parsing of timestamps</b>

           $ systemd-analyze timestamp yesterday now tomorrow
             Original form: yesterday
           Normalized form: Mon 2019-05-20 00:00:00 CEST
                  (in UTC): Sun 2019-05-19 22:00:00 UTC
              UNIX seconds: @15583032000
                  From now: 1 day 9h ago

             Original form: now
           Normalized form: Tue 2019-05-21 09:48:39 CEST
                  (in UTC): Tue 2019-05-21 07:48:39 UTC
              UNIX seconds: @1558424919.659757
                  From now: 43us ago

             Original form: tomorrow
           Normalized form: Wed 2019-05-22 00:00:00 CEST
                  (in UTC): Tue 2019-05-21 22:00:00 UTC
              UNIX seconds: @15584760000
                  From now: 14h left

   <b>systemd-analyze timespan </b><i>EXPRESSION</i>...
       This command parses a time span (i.e. a difference between two
       timestamps) and outputs the normalized form and the equivalent
       value in microseconds. The time span should adhere to the syntax
       documented in <a href="https://man7.org/linux/man-pages/man7/systemd.time.7.html">systemd.time(7)</a>, section "PARSING TIME SPANS".
       Values without units are parsed as seconds.

       <b>Example 14. Show parsing of timespans</b>

           $ systemd-analyze timespan 1s 300s '1year 0.000001s'
           Original: 1s
                 μs: 1000000
              Human: 1s

           Original: 300s
                 μs: 300000000
              Human: 5min

           Original: 1year 0.000001s
                 μs: 31557600000001
              Human: 1y 1us

   <b>systemd-analyze cat-config </b><i>NAME</i>|<i>PATH</i>...
       This command is similar to <b>systemctl cat</b>, but operates on config
       files. It will copy the contents of a config file and any
       drop-ins to standard output, using the usual systemd set of
       directories and rules for precedence. Each argument must be
       either an absolute path including the prefix (such as
       /etc/systemd/logind.conf or /usr/lib/systemd/logind.conf), or a
       name relative to the prefix (such as systemd/logind.conf).

       <b>Example 15. Showing logind configuration</b>

           $ systemd-analyze cat-config systemd/logind.conf
           # /etc/systemd/logind.conf
           ...
           [Login]
           NAutoVTs=8
           ...

           # /usr/lib/systemd/logind.conf.d/20-test.conf
           ... some override from another package

           # /etc/systemd/logind.conf.d/50-override.conf
           ... some administrator override

   <b>systemd-analyze verify </b><i>FILE</i>...
       This command will load unit files and print warnings if any
       errors are detected. Files specified on the command line will be
       loaded, but also any other units referenced by them. The full
       unit search path is formed by combining the directories for all
       command line arguments, and the usual unit load paths. The
       variable <i>$SYSTEMD_UNIT_PATH</i> is supported, and may be used to
       replace or augment the compiled in set of unit load paths; see
       <a href="https://man7.org/linux/man-pages/man5/systemd.unit.5.html">systemd.unit(5)</a>. All units files present in the directories
       containing the command line arguments will be used in preference
       to the other paths.

       The following errors are currently detected:

       •   unknown sections and directives,

       •   missing dependencies which are required to start the given
           unit,

       •   man pages listed in <i>Documentation=</i> which are not found in the
           system,

       •   commands listed in <i>ExecStart=</i> and similar which are not found
           in the system or not executable.

       <b>Example 16. Misspelt directives</b>

           $ cat ./user.slice
           [Unit]
           WhatIsThis=11
           Documentation=man:nosuchfile(1)
           Requires=different.service

           [Service]
           Description=x

           $ systemd-analyze verify ./user.slice
           [./user.slice:9] Unknown lvalue 'WhatIsThis' in section 'Unit'
           [./user.slice:13] Unknown section 'Service'. Ignoring.
           Error: org.freedesktop.systemd1.LoadFailed:
              Unit different.service failed to load:
              No such file or directory.
           Failed to create user.slice/start: Invalid argument
           user.slice: man nosuchfile(1) command failed with code 16

       <b>Example 17. Missing service units</b>

           $ tail ./a.socket ./b.socket
           ==&gt; ./a.socket &lt;==
           [Socket]
           ListenStream=100

           ==&gt; ./b.socket &lt;==
           [Socket]
           ListenStream=100
           Accept=yes

           $ systemd-analyze verify ./a.socket ./b.socket
           Service a.service not loaded, a.socket cannot be started.
           Service b@0.service not loaded, b.socket cannot be started.

   <b>systemd-analyze security [</b><i>UNIT</i>...]
       This command analyzes the security and sandboxing settings of one
       or more specified service units. If at least one unit name is
       specified the security settings of the specified service units
       are inspected and a detailed analysis is shown. If no unit name
       is specified, all currently loaded, long-running service units
       are inspected and a terse table with results shown. The command
       checks for various security-related service settings, assigning
       each a numeric "exposure level" value, depending on how important
       a setting is. It then calculates an overall exposure level for
       the whole unit, which is an estimation in the range 0.0...10.0
       indicating how exposed a service is security-wise. High exposure
       levels indicate very little applied sandboxing. Low exposure
       levels indicate tight sandboxing and strongest security
       restrictions. Note that this only analyzes the per-service
       security features systemd itself implements. This means that any
       additional security mechanisms applied by the service code itself
       are not accounted for. The exposure level determined this way
       should not be misunderstood: a high exposure level neither means
       that there is no effective sandboxing applied by the service code
       itself, nor that the service is actually vulnerable to remote or
       local attacks. High exposure levels do indicate however that most
       likely the service might benefit from additional settings applied
       to them.

       Please note that many of the security and sandboxing settings
       individually can be circumvented — unless combined with others.
       For example, if a service retains the privilege to establish or
       undo mount points many of the sandboxing options can be undone by
       the service code itself. Due to that is essential that each
       service uses the most comprehensive and strict sandboxing and
       security settings possible. The tool will take into account some
       of these combinations and relationships between the settings, but
       not all. Also note that the security and sandboxing settings
       analyzed here only apply to the operations executed by the
       service code itself. If a service has access to an IPC system
       (such as D-Bus) it might request operations from other services
       that are not subject to the same restrictions. Any comprehensive
       security and sandboxing analysis is hence incomplete if the IPC
       access policy is not validated too.

       <b>Example 18. Analyze systemd-logind.service</b>

           $ systemd-analyze security --no-pager systemd-logind.service
             NAME                DESCRIPTION                              EXPOSURE
           ✗ PrivateNetwork=     Service has access to the host's network      0.5
           ✗ User=/DynamicUser=  Service runs as root user                     0.4
           ✗ DeviceAllow=        Service has no device ACL                     0.2
           ✓ IPAddressDeny=      Service blocks all IP address ranges
           ...
           → Overall exposure level for systemd-logind.service: 4.1 OK 🙂
</pre>